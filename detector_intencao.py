import os
from fastapi import FastAPI
from pydantic import BaseModel
import pandas as pd
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
import shutil
from dotenv import load_dotenv

# âœ… Carregar variÃ¡veis de ambiente
load_dotenv()

# âœ… FunÃ§Ã£o para carregar documentos da pasta "docs"
def load_documents(directory="docs"):
    texts = []
    intents = []

    # Verifica se a pasta existe
    if not os.path.exists(directory):
        os.makedirs(directory)  # Cria a pasta se nÃ£o existir
        return texts, intents

    # ğŸ”„ Percorre todos os arquivos na pasta
    for file in os.listdir(directory):
        file_path = os.path.join(directory, file)
        ext = file.split(".")[-1]

        # ğŸ“„ Processa arquivos CSV (mensagem e intenÃ§Ã£o)
        if ext == "csv":
            df = pd.read_csv(file_path, sep=";", dtype=str)
            texts.extend(df["mensagem"].tolist())   # Salva mensagens
            intents.extend(df["intencao"].tolist()) # Salva intenÃ§Ãµes

    return texts, intents

# âœ… Carregar documentos e criar embeddings
texts, intents = load_documents()
if not texts:
    raise FileNotFoundError("Nenhum arquivo CSV encontrado na pasta 'docs'!")

print(f"ğŸ“‚ Total de entradas no CSV: {len(texts)}")

# ğŸ”„ Remover Ã­ndice FAISS antigo e recriar
if os.path.exists("faiss_index"):
    shutil.rmtree("faiss_index")

embeddings = OpenAIEmbeddings()
text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)
documents = text_splitter.create_documents(texts)  # âš ï¸ AlteraÃ§Ã£o aqui!
vectorstore = FAISS.from_documents(documents, embeddings)  # âš ï¸ Agora usa documentos fragmentados!
retriever = vectorstore.as_retriever(search_kwargs={"score_threshold": 0.7})  # âš ï¸ Adicionado limiar de confianÃ§a

print(f"ğŸ“¦ Total de documentos no FAISS: {len(vectorstore.index_to_docstore_id)}")

# ğŸ” Teste FAISS manualmente
test_query = "agendar horÃ¡rio"
test_results = retriever.invoke(test_query)
print(f"ğŸ›  Teste FAISS (busca por '{test_query}'): {test_results}")

# âœ… Criar a API FastAPI
app = FastAPI()

class Pergunta(BaseModel):
    pergunta: str

@app.post("/chat")
def chat(pergunta: Pergunta):
    print(f"ğŸ” Buscando intenÃ§Ã£o para: {pergunta.pergunta}")
    context_docs = retriever.invoke(pergunta.pergunta)[:1]  # Retorna apenas o documento mais relevante
    print(f"ğŸ“ Resultados encontrados: {context_docs}")

    if not context_docs:
        return {"intencoes": []}  # Se nÃ£o encontrar nada, retorna lista vazia

    # ğŸ“Œ Filtrar documentos com baixa similaridade
    matched_intents = []
    for doc in context_docs:
        if hasattr(doc, "score") and doc.score < 0.7:
            print("âš ï¸ Baixa similaridade! Ignorando resultado irrelevante.")
            continue  # Ignora resultados com baixa similaridade

        # ğŸ“Œ Associar mensagens Ã s intenÃ§Ãµes
        mensagem_normalizada = doc.page_content.strip().lower()
        for original, intent in zip(texts, intents):
            if mensagem_normalizada == original.strip().lower():
                matched_intents.append({"mensagem": original, "intencao": intent})
                break  # Garante que sÃ³ pega uma intenÃ§Ã£o por documento

    if not matched_intents:
        return {"intencoes": []}  # Se nÃ£o houver correspondÃªncia vÃ¡lida, retorna vazio

    print(f"âœ… IntenÃ§Ãµes retornadas: {matched_intents}")
    return {"intencoes": matched_intents}
